{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72546b35",
   "metadata": {},
   "source": [
    "Rupesh Bharambe (AI3107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca113e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rupes\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846b8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "url = \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    "file_path = \"nietzsche.txt\"\n",
    "if not os.path.exists(file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b58e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ee382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary processing\n",
    "chars = sorted(list(set(text)))\n",
    "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx2char = {i: ch for ch, i in char2idx.items()}\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1008b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequences\n",
    "seq_length = 100\n",
    "step = 1\n",
    "sequences = []\n",
    "targets = []\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i:i+seq_length])\n",
    "    targets.append(text[i+seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a19e481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(seq):\n",
    "    return [char2idx[ch] for ch in seq]\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = [vectorize(seq) for seq in sequences]\n",
    "        self.targets = [char2idx[ch] for ch in targets]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx]), torch.tensor(self.targets[idx])\n",
    "\n",
    "dataset = CharDataset(sequences, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fbbffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM model\n",
    "class LSTMTextGen(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hidden\n",
    "\n",
    "model = LSTMTextGen(vocab_size, hidden_size=256, num_layers=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36f74963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4644\n",
      "Epoch 2, Loss: 1.4616\n",
      "Epoch 3, Loss: 1.3060\n",
      "Epoch 4, Loss: 1.1291\n",
      "Epoch 5, Loss: 1.2719\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for inputs, labels in dataloader:\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961c0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nietzsche said: as not no latterly, the happiness--and alw-leng to be\n",
      "imaging suffer swip as we truth, and no goal from lifest and mode you hat-philosopherse world upon thoughts of learn alassi-Goside. Thoiles, bying?--Moral truth, and the ullat? Indowed to us now\n",
      "lution is power Gretctest afterwards altogracting i\n"
     ]
    }
   ],
   "source": [
    "# Text generation\n",
    "def generate_text(model, start_str, length=200):\n",
    "    model.eval()\n",
    "    input_seq = torch.tensor([char2idx[c] for c in start_str]).unsqueeze(0)\n",
    "    generated = start_str\n",
    "\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            output, hidden = model(input_seq[:, -seq_length:], hidden)\n",
    "            prob = torch.softmax(output, dim=1).squeeze()\n",
    "            idx = torch.multinomial(prob, num_samples=1).item()\n",
    "            generated += idx2char[idx]\n",
    "            input_seq = torch.cat([input_seq, torch.tensor([[idx]])], dim=1)\n",
    "    return generated\n",
    "\n",
    "print(generate_text(model, \"Nietzsche said: \", 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026f7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
