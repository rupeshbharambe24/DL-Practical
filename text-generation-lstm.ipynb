{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72546b35",
   "metadata": {},
   "source": [
    "Rupesh Bharambe (AI3107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca113e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846b8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
    "text = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b58e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean and tokenize\n",
    "text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())  # remove punctuation and lowercase\n",
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ee382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "vocab = sorted(set(words))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1008b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "sequence_length = 5\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(len(words) - sequence_length):\n",
    "    seq = words[i:i + sequence_length]\n",
    "    target = words[i + sequence_length]\n",
    "    inputs.append([word2idx[w] for w in seq])\n",
    "    targets.append(word2idx[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19e481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WordDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.x = torch.tensor(inputs)\n",
    "        self.y = torch.tensor(targets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "dataset = WordDataset(inputs, targets)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "class LSTMWordGen(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output[:, -1, :])  # only last output\n",
    "        return output\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "model = LSTMWordGen(vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74fbbffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.0866\n",
      "Epoch 2, Loss: 4.8182\n",
      "Epoch 3, Loss: 4.1361\n",
      "Epoch 4, Loss: 3.4140\n",
      "Epoch 5, Loss: 2.3527\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for x_batch, y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x_batch)\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36f74963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rabbit hole was very likely true down down down down her face brightened up at the top of his voice and was going to begin again for some time without interrupting and began to\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_words(model, seed_text, num_words=20):\n",
    "    model.eval()\n",
    "    words = seed_text.lower().split()\n",
    "    for _ in range(num_words):\n",
    "        input_seq = [word2idx.get(w, 0) for w in words[-sequence_length:]]\n",
    "        input_tensor = torch.tensor(input_seq).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            out = model(input_tensor)\n",
    "            pred_idx = torch.argmax(out, dim=1).item()\n",
    "            words.append(idx2word[pred_idx])\n",
    "    return ' '.join(words)\n",
    "\n",
    "seed = \"the rabbit hole was very\"\n",
    "print(generate_words(model, seed, 30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026f7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch GPU)",
   "language": "python",
   "name": "pytorch-gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
